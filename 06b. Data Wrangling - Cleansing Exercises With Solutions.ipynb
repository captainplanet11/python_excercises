{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains credit card default information of clients in Taiwan. An entire modeling methodology is explored, starting from the basics of data exploration and treatment and ending by exploring different techniques for predictive analytics (logistic regression, decision trees, gradient boosting, etc.) <br>\n",
    "\n",
    "What follows is a brief description of the 25 variables:\n",
    "<b>ID</b>: ID of each client\n",
    "<b>LIMIT_BAL</b>: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "<b>SEX</b>: Gender (1 = male; 2 = female).\n",
    "<b>EDUCATION</b>: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "<b>MARRIAGE</b>: Marital status (1 = married; 2 = single; 3 = others).\n",
    "<b>AGE</b>: Age (year).\n",
    "\n",
    "History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows:\n",
    "\n",
    "<b>PAY_0</b>:  the repayment status in September, 2005;\n",
    "<b>PAY_2</b>: the repayment status in August, 2005; . . .;\n",
    "<b>PAY_3</b>: . . .\n",
    "<b>PAY_4</b>: . . .\n",
    "<b>PAY_5</b>: . . .>\n",
    "<b>PAY_6</b>: the repayment status in April, 2005. \n",
    "The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "\n",
    "Amount of bill statement (NT dollar).\n",
    "\n",
    "<b>BILL_AMT1</b>: amount of bill statement in September, 2005;\n",
    "<b>BILL_AMT2</b>: amount of bill statement in August, 2005; . . .;\n",
    "<b>BILL_AMT3</b>: . . .;\n",
    "<b>BILL_AMT4</b>: . . .;\n",
    "<b>BILL_AMT5</b>: . . .;\n",
    "<b>BILL_AMT6</b>: amount of bill statement in April, 2005.\n",
    "\n",
    "Amount of previous payment (NT dollar).\n",
    "\n",
    "<b>PAY_AMT1</b>: amount paid in September, 2005;\n",
    "<b>PAY_AMT2</b>: amount paid in August, 2005; . . .;\n",
    "<b>PAY_AMT3</b>: . . .;\n",
    "<b>PAY_AMT4</b>: . . .;\n",
    "<b>PAY_AMT5</b>: . . .;\n",
    "<b>PAY_AMT6</b>: amount paid in April, 2005;\n",
    "<b>default.payment.next.month</b>: payment default (1 = yes; 2 = no)\n",
    "\n",
    "<b>References/Sources:</b>\n",
    "\n",
    "[1]UCI ML Repository: https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "[2] Lichman, M. (2013). UCI Machine Learning Repository http://archive.ics.uci.edu/ml. Irvine, CA: University of California, School of Information and Computer Science.<br>\n",
    "[3] Name: I-Cheng Yeh \n",
    "email addresses: (1) icyeh '@' chu.edu.tw (2) 140910 '@' mail.tku.edu.tw \n",
    "institutions: (1) Department of Information Management, Chung Hua University, Taiwan. (2) Department of Civil Engineering, Tamkang University, Taiwan. \n",
    "other contact information: 886-2-26215656 ext. 3181 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "print(\"Importing required libraries\")\n",
    "import pandas as pd\n",
    "import os, boto3, subprocess, re, sys, gc\n",
    "from botocore.client import Config\n",
    "\n",
    "print(\"All libraries successfully loaded!\")\n",
    "\n",
    "kms_key = os.environ['AW_S3_ENCRYPTION_KEY']\n",
    "\n",
    "bucket_name = os.environ['AW_S3_STORAGE_BUCKET']\n",
    "storage_key = os.environ['AW_S3_STORAGE_KEY'] + '/awdata/rawfiles/'\n",
    "full_s3_location = 's3://' + bucket_name + '/' + storage_key \n",
    "print(\"full_s3_location: '{}'\".format(full_s3_location))\n",
    "\n",
    "#raw_df= pd.read_csv(full_s3_location + \"sampled_ssme_app_data1.csv.gz\", compression='gzip',encoding = 'iso8859_11')\n",
    "df_twn= pd.read_csv(full_s3_location + \"UCI_Credit_Card.csv\")\n",
    "z.show(df_twn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Are there any duplicates in \"ID\" ? \n",
    "2. How many distinct \"AGE\" values it has?\n",
    "\n",
    "``NOTE`` - Without using the ``groupby`` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn[['ID']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn[['AGE']].drop_duplicates().shape[0]\n",
    "\n",
    "# df_twn[['AGE']].nunique() # number of unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a code to replace the 'SEX' values 1 to 'male' and 2 to 'female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn['SEX'].replace([1,2],['male', 'female']).head()\n",
    "# Note that the column type changed automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Write a script to bin \"LIMIT_BAL\" into \\\\(2\\\\) groups: one \\\\(\\lt\\\\) than the average value and another \\\\(\\geq\\\\) than average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "bins = [df_twn[\"LIMIT_BAL\"].min(),df_twn[\"LIMIT_BAL\"].mean(),df_twn[\"LIMIT_BAL\"].max()]\n",
    "\n",
    "pd.cut(df_twn[\"LIMIT_BAL\"],bins, include_lowest = True).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Write a Python script to divide the \"BILL_AMT1\" values into 5 equally populated bins:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pd.qcut(df_twn['BILL_AMT1'],5).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to bin a given list, containing numeric variables, in three equally sized categorys and return all of them with prefix =  \"categ_\" along with all the other variables without changing the oringal data.\n",
    "\n",
    "Run the function on all \"BILL_AMT\" variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "def automatic_bin(df,numeric_list,q):\n",
    "    df_aux = df.copy()\n",
    "    for names in numeric_list:\n",
    "        df_aux[\"categ_\" + names] = pd.qcut(df_aux[names],q)\n",
    "    \n",
    "    return df_aux \n",
    "        \n",
    "new_df_twn = automatic_bin(df_twn,['BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5', 'BILL_AMT6'] ,3)\n",
    "df_twn.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a script to show all the values in the dataframe where the absolute \"LIMIT_BAL\" value is greater than 500,000.00\n",
    "\n",
    "``NOTE`` - Without using ``.loc`` or ``.iloc``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "z.show(df_twn[abs(df_twn['LIMIT_BAL']) > 500000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the data you created at the Exercise 5:\n",
    "\n",
    "Modify the function to return all the dummies along with all the other variables (including the new created variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "def automatic_bin(df,numeric_list,q):\n",
    "    df_aux = df.copy()\n",
    "    for names in numeric_list:\n",
    "        df_aux[\"categ_\" + names] = pd.qcut(df_aux[names],q, labels =  [1, 2, 3])\n",
    "        df_aux = df_aux.join(pd.get_dummies(df_aux[\"categ_\" + names], prefix = 'D_'+names))\n",
    "    \n",
    "    return df_aux \n",
    "    \n",
    "new_df_twn = automatic_bin(df_twn,['BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5', 'BILL_AMT6'] ,3)\n",
    "new_df_twn.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.0.0",
   "language": "python",
   "name": "spark2"
  },
  "language_info": {
   "codemirror_mode": "text/python",
   "file_extension": ".py",
   "mimetype": "text/python",
   "name": "scala",
   "pygments_lexer": "python",
   "version": "3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
