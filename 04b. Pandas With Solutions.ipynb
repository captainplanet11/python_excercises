{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a continuation of the 04b. Pandas (With Solutions) Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os, boto3, subprocess, re, sys, gc\n",
    "from botocore.client import Config\n",
    "\n",
    "print(\"All libraries successfully loaded!\")\n",
    "\n",
    "kms_key = os.environ['AW_S3_ENCRYPTION_KEY']\n",
    "\n",
    "bucket_name = os.environ['AW_S3_STORAGE_BUCKET']\n",
    "storage_key = os.environ['AW_S3_STORAGE_KEY'] + '/awdata/rawfiles/'\n",
    "full_s3_location = 's3://' + bucket_name + '/' + storage_key \n",
    "print(\"full_s3_location: '{}'\".format(full_s3_location))\n",
    "df_twn= pd.read_csv(full_s3_location + \"UCI_Credit_Card.csv\",nrows=100)\n",
    "should_be_str = ['SEX','EDUCATION', 'MARRIAGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','default.payment.next.month']\n",
    "df_twn[should_be_str] = df_twn[should_be_str].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assign a new column to a DataFrame we could use the general syntax: \n",
    "````\n",
    "df['NewColumn'] = Values\n",
    "df['NewColumn'] = df['Col1'] + df['Col2'] # other calculation\n",
    "````\n",
    "\n",
    "Similarly, to delete a column we can use `del`: \n",
    "````\n",
    "del df['NewColumn']\n",
    "````\n",
    "If we want to delete several columns at once, we can use `drop`. \n",
    "````\n",
    "df.drop(['Column1',...,'ColumnN'],axis=1,inplace=True)\n",
    "````\n",
    "The method `inplace` in the expression above indicates that the DataFrame is <b>permanently</b> modified (in fact, it deletes the original dataframe and constructs a new one with the new desired modification). When we set `axis = 1`, that indicates the dimension of the columns, rather than the rows (`axis = 0`). If in the previous expression there was no `inplace` (e.g. the default of inplace=False), the original dataframe would have kept the dropped columns, as they would simply perform the desired function but not modify the data. \n",
    "\n",
    "For example, we can add a new column named <i>Company</i> to an existing dataframe and assign \"FICO\" as the value, as shown below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':[1,2,3,4,5],'name':['Calvin','Ron','Daisy','Jasmine','Juan'],'income':[20000,40000,20000,10000,50000]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df['Company'] = 'FICO'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 3 new columns to df_twn:\n",
    "\n",
    "1. **PCT_PAY** =  **PAY_AMT1** divide by **BILL_AMT1**\n",
    "2. **EDUCATION_MARRIAGE** = Combine the two variables in a single string\n",
    "3. **Categ_LIMIT**:\n",
    "    * If  LIMIT_BAL < 100000 then \"LOW\"\n",
    "    * Else if LIMIT_BAL < 300000 then \"MEDIUM\"\n",
    "    * Else \"HIGH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn['PCT_PAY'] = df_twn['PAY_AMT1']/df_twn['BILL_AMT1']\n",
    "print(df_twn['PCT_PAY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn['EDUCATION_MARRIAGE'] = (df_twn['EDUCATION'].astype(\"str\") + df_twn['MARRIAGE'].astype(\"str\")).astype(\"str\", inplace = True)\n",
    "df_twn[['EDUCATION','MARRIAGE','EDUCATION_MARRIAGE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn['Categ_LIMIT'] = 'HIGH'\n",
    "df_twn.loc[df_twn['LIMIT_BAL'] < 300000, 'Categ_LIMIT'] = 'MEDIUM'\n",
    "df_twn.loc[df_twn['LIMIT_BAL'] < 100000, 'Categ_LIMIT'] = 'LOW'\n",
    "print(df_twn['Categ_LIMIT'].describe())\n",
    "z.show(df_twn[['LIMIT_BAL','Categ_LIMIT']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to delete a column (e.g. \"Company\") from df, one way to do this is with the python (not pandas) keyword `del`\n",
    "\n",
    "The `del` keyword is used to delete objects. In Python everything is an object, so the del keyword can also be used to delete columns (series), dataframes, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':[1,2,3,4,5],'name':['Calvin','Ron','Daisy','Jasmine','Juan'],'income':[20000,40000,20000,10000,50000]})\n",
    "print(\"original:\\n\",df)\n",
    "del df['name']\n",
    "print(\"after del: \\n\",df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(16).reshape(4,4),columns=['col1','col2','col3','col4'],index=['ind1','ind2','ind3','ind4'])\n",
    "print(\"original: \\n\",df1)\n",
    "df1.drop(['col1','col2'],axis=1,inplace=True)\n",
    "print(\"\\nafter drop: \\n\",df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has 3 different types of ``map`` methods:\n",
    "\n",
    "1. **applymap**:\n",
    "    * This method works only for **DataFrames** and will apply a function __element-wise__\n",
    "    * Accepts functions\n",
    "\n",
    "2. **apply**:\n",
    "    * This method works for both **Series** and **Dataframe** and will apply a function to a column or row (if it's a DataFrame).\n",
    "    * Works element-wise and can be used for data aggregation\n",
    "    * Accepts functions\n",
    "\n",
    "3. **map**:\n",
    "    * This method works only for **Series** and is better used to substitute all the values with another ones\n",
    "    * Accepts dicts, Series or function objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn[[\"PAY_AMT1\",'BILL_AMT1']].applymap(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn[[\"PAY_AMT1\",'BILL_AMT1']].apply(lambda x: (x - np.mean(x))/np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn[[\"PAY_AMT1\",'BILL_AMT1']].apply(lambda x:(np.mean(x))/np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn[['PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5']].apply(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn[['PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5']].apply(np.sum, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn['AGE'].apply(lambda x: str(x) + \" year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn['AGE'].map(lambda x: str(x) + \" year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn['SEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn['SEX'].map({\"1\":\"Sex_1\",\"2\":\"Sex_2\"})\n",
    "# df_twn['SEX'].map({\"1\":\"Sex_1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following random pandas DataFrame: \n",
    "````\n",
    "df = pd.DataFrame(np.random.randn(16).reshape(4,4))\n",
    "````\n",
    "1. Create an <b>anonymous</b> `lambda` general function, that computes the difference between the mininum (`min()`) and maximum (`max()`) values for any given array (or list of values).\n",
    "2. Using the result above, apply the function on the previous DataFrame (use `axis = 1`).\n",
    "3. Repeat the exercise above, but this time apply the function on `axis = 0`. \n",
    "4. What is the difference between the results? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df = pd.DataFrame(np.random.randn(16).reshape(4,4))\n",
    "\n",
    "print('DataFrame is: \\n',df)\n",
    "\n",
    "\n",
    "## defining an anonymous lambda function\n",
    "\n",
    "f = lambda x: x.max() - x.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "print('axis = 0')\n",
    "print(df.apply(f))\n",
    "\n",
    "# df.apply(lambda x: x.max() - x.min())\n",
    "print(' ')\n",
    "print('axis = 1')\n",
    "print(df.apply(f,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `axis = 0` calculates the difference between maximum and minimum values for each row whereas `axis = 1` calculates the difference to each column.\n",
    "\n",
    "<b>Note:</b> there are statistical functions that can be used instead of `apply` (`mean()`, `sum()`, `max()`,`min()`, `std()`, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the twn_df dataframe, imagine that we want to create a new function `PAY_02` where:\n",
    "\n",
    "* If 'PAY_0' equal then 'PAY_2' then combine\n",
    "* else return \"0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn['PAY_02'] = df_twn[['PAY_0','PAY_2']].apply(lambda x: x['PAY_0'] + x['PAY_2'] if x['PAY_0'] == x['PAY_2'] else \"0\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing records with `AGE` greater than 35 vs. those with `AGE` less than or equal to 35, which group has a higher average LIMIT_BAL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "print(\"Age > 35: \",df_twn.loc[df_twn['AGE'] > 35, 'LIMIT_BAL'].mean())\n",
    "print(\"Age <= 35: \",df_twn.loc[df_twn['AGE'] <= 35, 'LIMIT_BAL'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important operation is \"sorting\". It involves sorting a specific column using some criterion (i.e. highest to lowest value or vice-versa). Pandas provides some methods for sorting, such as \n",
    "\n",
    "```Python\n",
    "# Sort index or column labels.\n",
    "sort_index(ascending=True, axis = 0, inplace = False)\n",
    "\n",
    "# Sort values from columns\n",
    "sort_values(ascending=True, axis = 0,  inplace = False)\n",
    "\n",
    "# Compute numerical data ranks (1 to n)\n",
    "rank(axis = 0)\n",
    "```\n",
    "For example, we can sort the following dataframe by its column names: \n",
    "\n",
    "````\n",
    "df = pd.DataFrame(np.arange(8).reshape((2, 4)),index=['three', 'one'],columns=['d', 'a', 'b', 'c'])\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df = pd.DataFrame(np.arange(8).reshape((2, 4)),index=['three', 'one'],columns=['d', 'a', 'b', 'c'])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[1,5,4,7,-3],'b':[55,32,-66,-44,1],'c':[1,6,3,33,-55]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "print(df.sort_values(by=['a','b']))\n",
    "print(\"\\nThis is df: \\n\",df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': [5.2, 6, -3, 2], 'b': [1, 1, 1, 1],'c': [-2, 5, 8, -2.5]})\n",
    "print(\"df: \\n\",df)\n",
    "print(\"\\ndf.rank():\\n\",df.rank())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First select the 10 rows with the highest PAY_AMT1. \n",
    "* From them, select the 2 with the lowest BILL_AMT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "first_sort = df_twn.sort_values('PAY_AMT1', ascending = False)[0:10]\n",
    "second_sort = first_sort.sort_values('BILL_AMT1')[0:2]\n",
    "print(second_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last - but not the least - topic covered in the `pandas` module is data aggregation and \"GroupBy\" operations. Data aggregation refers to transformations that produce scalar values (e.g. mean, count, sum, etc. - as we've seen before). The general syntax to group a dataframe by some particular column and apply a function to another particular column is as follows: \n",
    "````\n",
    "df.groupby(['VAR_1',...'VAR_N'])[['var_1',...,'var_n']].agg([function_1,...,function_n])\n",
    "````\n",
    "In this section we will look at the following applications of the `groupby` function: \n",
    "\n",
    "1. **iterations over groups**\n",
    "2. **groupby operations using dictionaries and Series**\n",
    "3. **groupby operations using functions**\n",
    "4. **groupby operations using index levels**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "df = pd.DataFrame({'ID' : ['X','X','Y','Z','A','B','Z','X','Y','Z'],\n",
    "                   'State' : ['Ohio','California','California','Ohio','Ohio','Arkansas','Hawaii','Hawaii','Arkansas','California'],\n",
    "                   'data1' : np.random.randn(10),\n",
    "                   'data2' : np.random.randn(10)})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a GroupBy object to group df by the values in the \"ID\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.groupby(['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object we just created can be used to apply several computations in a dataframe. Calculate the median of the numerical columns by grouping the dataframe by State.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.groupby(['State']).median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the dataframe by 'State' and calculate the median value of the column 'data2' (only)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "print(type(df['data2']))\n",
    "print(type())\n",
    "df['data2'].groupby(df['State']).median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the difference between both syntaxes (grouping the entire dataframe versus a single column) shown above in questions 15 & 16? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Answer 15:  \n",
    "* We use pandas.<font color=red>DataFrame</font>.groupby\n",
    "* We get the desired groups (by State) by specifying them as a list.\n",
    "\n",
    "In Answer 16:\n",
    "* We use pandas.<font color=red>Series</font>.groupby\n",
    "* We get the desired groups (by State) by specifying them as a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the median of column 'data2' by both keys (the combination of ID and State).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df['data2'].groupby([df['ID'],df['State']]).median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Count the number of records within each unique combination of ID and State.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.groupby(['ID','State']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following syntax allows one to visualize and apply complex operations to each pair name-group in a GroupBy object: \n",
    "\n",
    "````\n",
    "for name, group in df.groupby('ID'): \n",
    "...\n",
    "````\n",
    "\n",
    "What would be the code to loop over a `groupby` object in the case of multiple keys? (Assume the keys are 'ID' and 'State').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "for (i,j), group in df.groupby(['ID','State']): \n",
    "    print(i,j)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen the usage of dictionaries applied to dataframes. Convert the groupby object we just created into a dictionary to visualize the 'pieces' of the previous script in dictionary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "print(df,\"\\n\")\n",
    "d =dict(list(df.groupby(['ID','State'])))\n",
    "\n",
    "print(\"d.keys():\\n\",d.keys(),\"\\n\")\n",
    "\n",
    "print(\"type(d.values()):\\n\",type(d.values()),\"\\n\")\n",
    "\n",
    "print(\"d.items()\\n\",d.items(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can can also select a subset of columns when using groupby such as : \n",
    "\n",
    "````\n",
    "df.groupby('State')['ID']\n",
    "````\n",
    "Compute the `mean` of data1 using the previous syntax applied to State and ID.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.groupby(['State','ID'])['data1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another form of applying `groupby` using a dictionary is by mapping the values in a dictionary such as: \n",
    "````\n",
    "mapping = {'Col1':'Column1','Col2':'Column2','Col3':'Column3'}\n",
    "df.groupby(mapping,axis=1)\n",
    "````\n",
    "Use the dictionary below to compute the sum: \n",
    "````\n",
    "my_dict = {'data1':'BirthRate','data2':'DeathRate','data3':'AssaultRate'} \n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "print(df,\"\\n\")\n",
    "my_dict = {'data1':'BirthRate','data2':'DeathRate','data3':'AssaultRate'} \n",
    "\n",
    "df.groupby(my_dict,axis=1).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to calculate several different functions using `groupby`. The method implemented in pandas is: \n",
    "````\n",
    "df.groupby('key').agg('function')\n",
    "````\n",
    "We can also apply a list of functions to be computed, such as: \n",
    "\n",
    "````\n",
    "[function1, function2, ..., functionN]\n",
    "````\n",
    "\n",
    "a) Write a function to compute the distance between the maximum value and the mean value of the data columns for each US State.\n",
    "\n",
    "b) Compute the mean, median, maximum, minimum (for each numeric column) and count the values for each 'ID'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "def MaxToMean(data):\n",
    "    return abs(round(data.max() - data.mean(),2))\n",
    "\n",
    "print(df.groupby('State').agg(MaxToMean))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "print(df.groupby('ID').agg(['mean','median','max','min','count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute (on a single column!) all the statistics provided by the previous functions only for ID=X. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "print(df)\n",
    "print(df.groupby('ID').agg(['mean','median','max','min','count']).transpose()['X'],\"\\n\")\n",
    "print(df.groupby('ID').agg(['mean','median','max','min','count']).loc[\"X\",:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use tuples to convert the name of the column computed into something else. Change the previous code to print 'Function1', ... , 'FunctionN' to each of the functions computed before grouped by ID for all IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "FuncsList = [('Function1','mean'),\n",
    "             ('Function2','median'),\n",
    "             ('Function3','max'),\n",
    "             ('Function4','min'),\n",
    "             ('Function5','count')]\n",
    "\n",
    "df.groupby('ID').agg(FuncsList).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to apply different functions to different columns using a dictionary. \n",
    "\n",
    "For each value of State:\n",
    "\n",
    "* Calculate the maximum, minimum and count of the data1 column\n",
    "* Calcykate the mean, median and the function we defined (MaxToMedian) of the data2 column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "funcs_dict = {'data1':['min','max','count'],'data2':['mean','median',MaxToMean]}\n",
    "\n",
    "df.groupby('State').agg(funcs_dict).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have previously seen the 'apply' method, useful to compute functions in a given column. Its capabilities are stronger when used together with GroupBy. \n",
    "\n",
    "a) Write a function such as : $$f(x,n) = [x_1, x_2, ..., x_n]^2$$ to compute the square of each element in a list, where n is any length we want, restricted by the maximum number of rows in the dataframe.\n",
    "\n",
    "b) Use the function defined above and `apply` to both data1 and data2 of each US State. (do it iteratively starting with \\\\(n = 1\\\\) until n = number of rows).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "def Squared(x,n=1): \n",
    "    return (x**2)[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "nRows = df.shape[0]\n",
    "for i in range(nRows): \n",
    "    print(i + 1)\n",
    "    df.groupby('State')['data1','data2'].apply(Squared, n = (i+1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Answer the follow questions using df_twn\n",
    "\n",
    "1. Which 'EDUCATION' category has the highest average PAY_AMT1?\n",
    "2. Which 'MARRIAGE' category has the highest number of records with \"PAY_0\" equal 0 ?\n",
    "3. Create a table containing at least 6 statistical functions to analyze the \"LIMIT_BALL\" by \"EDUCATION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_twn.groupby(\"EDUCATION\")['PAY_AMT1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df_gb = df_twn.groupby([\"MARRIAGE\",\"PAY_0\"])[[\"ID\"]].count().reset_index()\n",
    "df_gb = df_gb.loc[df_gb['PAY_0'] == '0', :]\n",
    "df_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "z.show(df_twn.groupby('EDUCATION')['LIMIT_BAL'].agg(['mean','median','max','min','count','std','var']).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.0.0",
   "language": "python",
   "name": "spark2"
  },
  "language_info": {
   "codemirror_mode": "text/python",
   "file_extension": ".py",
   "mimetype": "text/python",
   "name": "scala",
   "pygments_lexer": "python",
   "version": "3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
