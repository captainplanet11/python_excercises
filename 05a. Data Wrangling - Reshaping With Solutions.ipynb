{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "The work of a data scientist consists of data wrangling roughly \\\\(80 \\% \\\\) of the time. It is one of the most difficult steps in the model development process. There are no recipees when it comes to data wrangling, but some best practices help the analyst to intensify the efficiency of the data wrangling process. In most cases, the data that the data scientist needs to analyze does not come from a single source or is contained in a single file. It is very often spread across a variety of files and databases. The `pandas` library provides many powerful tools to join and concatenate datasets, reshape them and to rearrange the data. Some of these features include:\n",
    "\n",
    "1. Hierarchical Indexation\n",
    "2. Combining and Merging Datasets\n",
    "3. Reshaping and Pivoting\n",
    "\n",
    "#### What is data wrangling? \n",
    "\n",
    "The process of data wrangling consists of structuring, aggregation and cleaning of data (some definitions also include data enrichment / characteristic generation). Some common activities where the term data wrangling can be applied include (but are not limited to): gathering data from different sources; understanding the sources and variables of different datasets; cleaning up the duplicates, blanks (filling in the missing values) and reducing errors in the data; joining entire datasets into a single table; variable generation (data enrichment); visualization of the data in order to remove outliers or other undesirable values in the data, etc.; In this module we explore the process of wrangling data using `pandas` and other Python functions.\n",
    "\n",
    "<b>Note (1):</b> This section is intended to be more \"hands-on\" so that the user can become more familiar with these techniques.\n",
    "<b>Note (2):</b> Refer to the `pandas` module to remember some of the syntax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very useful method to manipulate and transform a dataframe is `stack()` and `unstack()`. For example, taking the same dataframe that we have shown above, the `unstack()` method reduces the indices and transforms them into columns. See the example below: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(np.around(np.random.randn(10,5), decimals = 2),\n",
    "                  index=[['a','a','a','b','b','b','c','c','d','d'],\n",
    "                         [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 1 , 2]])\n",
    "\n",
    "z.show(df.unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stack()` is the inverse operation of `unstack()`. What's the output of the following operation?\n",
    "````\n",
    "df.unstack().stack()\n",
    "````\n",
    "#### `PLEASE DO NOT CODE`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ANSWER`\n",
    "\n",
    "The original dataframe does not change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows us to reorder a dataframe based on its index. In the case of a multi-index dataframe (as the one previously shown), we can access the first index using `level = 0` (`list('a','b','c','d')`) and the second index using `index = 1` (`list(1,2,3)`).\n",
    "\n",
    "We can change the arrangement of the data within the dataframe by sorting the index: \n",
    "````\n",
    "df.sort_index(level=1)\n",
    "````\n",
    "We can also swap the levels and change the index order:\n",
    "````\n",
    "df.swaplevel(0,1)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.sort_index(level=1)\n",
    "\n",
    "# The level is telling pandas wich level need to be sorted\n",
    "# In this case, it's is sorting the \"Second\" level (the index at positio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.swaplevel(0,1)\n",
    "\n",
    "# in this method, you need to input the two indeces to be swapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the expected output? \n",
    "````\n",
    "df.swaplevel(0,1).sort_index(level=0)\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.swaplevel(0,1).sort_index(level=0)\n",
    "\n",
    "# The first method is swapping the level 0 and 1\n",
    "# After this, the \"older\" level 1 is now level 0.\n",
    "# That's why the level with number is sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the expected output? \n",
    "````\n",
    "df.sort_index(level = 1)\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.sort_index(level = 1)\n",
    "\n",
    "# The result is the same as the Exercise 2 because the code in Exercise 2 didn't change the DataFrame permanently. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the output? \n",
    "````\n",
    "np.all(df.swaplevel(0,1).sort_index(level = 0).values == df.sort_index(level = 1).values)\n",
    "````\n",
    "#### `PLEASE DO NOT CODE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "# The first comparison will bring will compare each element between the two dataframes. If they are equal then it will return a True value (and False otherwise).\n",
    "\n",
    "# The Second step is the np.all(). It will return a True value if all the comparisons return True. If a single one comparison don`t return a True value, the final result will be False.\n",
    "\n",
    "# So, the output will be \"True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.swaplevel(0,1).sort_index(level = 0).values == df.sort_index(level = 1).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ANSWER`\n",
    "The returned values of the dataframe are indeed the same. Swapping levels and sorting by level 0 or straight sorting by level 1 is equivalent. The indexation is different, because in the first case we change the indices and in the second we keep them at the same original level. We can calso summarize results by applying calculations to different levels. For instance, the following calculation does the summation of all the values within the specified index level: \n",
    "````\n",
    "df.sum(level=0)\n",
    "````\n",
    "The output is shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.sum(level=0)\n",
    "\n",
    "# This is doing something very similar as a groupby method.. it's doing a sum by groupby the index level 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, one could apply the above expression at the `level = 1`. Can you guess how many rows the output will have given the expression below? \n",
    "````\n",
    "df.sum(level = 1)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.sum(level=1)\n",
    "\n",
    "# Since we have 3 unique values in the index leve = 1, the final result will be a dataframe with 3 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ANSWER`\n",
    "\n",
    "The final dataframe is a summary of the inner indices \\\\((1,2,3)\\\\). When we use `sum(level=1)` we are collapsing the external indices (a,b,c,d) and calculating all that is in between. We can also declare `sum(axis = 1)` or `sum(axis = 0)` in conjunction with `level = 0` or `level = 1`. Let's see what happens with the expression below.\n",
    "````\n",
    "df.sum(axis = 0)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.sum(axis=0)\n",
    "\n",
    "# If we put axis = 0, it will sum all the element by column\n",
    "\n",
    "# if we put axis = 1, it will sum all the elements by row\n",
    "\n",
    "#df.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the previous output, can you guess what happened? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ANSWER`\n",
    "The summation happened for each column (0,1,2,3,4) and the displayed results are the sum of every single value in each column. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the answer of exercise 7, what is the output of the following? \n",
    "````\n",
    "df.sum(axis = 1)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.sum(axis=1)\n",
    "\n",
    "# It's doing a sum by row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the previous script is the summation of the rows of the dataframe. We can play with this idea and explore it a bit further. What's the output of the following expression? A number or a dataframe? \n",
    "\n",
    "````\n",
    "df.sum(level=0,axis=0)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.sum(level = 0, axis = 0)\n",
    "#It has the same result as df.sum(level = 0)\n",
    "#because, by default the sum method has axis = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ANSWER` \n",
    "\n",
    "The result is a dataframe, because it first applies the `sum()` function to the `level  = 0` and then it can't 'collapse' anything else anymore (as there aren't any more levels in `axis = 0`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility to reshape a dataframe is by using its own columns as indices. For example, we could use the columns 0 and 1 as indices as follows: \n",
    "````\n",
    "df.set_index([0,1])\n",
    "````\n",
    "When we use `set_index()` we remove the existing indices and the original columns are also removed. We could keep the original columns by simply adding the statement `drop = False`.\n",
    "````\n",
    "df.set_index([0,1],drop=False)\n",
    "````\n",
    "Alternatively, a commonly used method is `reset_index()`. It is the opposite operation of `set_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.reset_index().set_index([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.set_index([0,1],drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you guess what is the outcome of the following expression (remember that our dataframe is still the same we started with)?\n",
    "````\n",
    "df.reset_index(level = 1)\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.reset_index(level = 1)\n",
    "# the reset_index method will transfer the index to a column.\n",
    "# If the dataframe doesn't have any other level index it will create a new one ine following format:\n",
    "# RangeIndex(start = 0, stop = n, step 1), where n = # rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use the following expression instead? \n",
    "````\n",
    "df.reset_index(level = 0)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.reset_index(level = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't declare the level we want to reset, what is the output? \n",
    "````\n",
    "df.reset_index()\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.reset_index()\n",
    "\n",
    "# If you don't tell pandas which index you want to reset, it will reset all of them\n",
    "# You can have the same result by doing df.reset_index(level = [0,1])\n",
    "# Pandas will automatically create a new index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that simply using `reset_index()` returns all the indices to the dataframe as columns. We could now work with the original indices as columns instead of rows. The method also accepts `inplace`, so, if one wants to permanently change a dataframe, it is very simple to do it. Knowing that reset_index() returns the indices to the columns, what number is printed in the following code? \n",
    "````\n",
    "df.reset_index().loc[2,0]\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.reset_index().loc[2,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, let's consider the two following dataframes: \n",
    "````\n",
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)})\n",
    "df2 = pd.DataFrame({'key': ['a', 'b', 'd'],'data2': range(3)})\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)})\n",
    "df2 = pd.DataFrame({'key': ['a', 'b','a', 'd'],'data2': range(4)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that `merge()` joins two distinct dataframes, what do you think is the output of the following expression? \n",
    "\n",
    "````\n",
    "import pandas as pd\n",
    "\n",
    "pd.merge(df1,df2)\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pd.merge(df1,df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened in the script above?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ANSWER`\n",
    "\n",
    "Because we didn't specify which 'key' we wanted to merge with, `pandas` does the merging using the overlapping column names as keys. We could, instead, use the following script to do the same work. \n",
    "````\n",
    "pd.merge(df1, df2, on='key')\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the column names are different between dataframes \\\\(1\\\\) and \\\\(2\\\\), we can use `left_on` and `right_on` instead of simply `on` to specify the column where we want to merge. Write the expression that combines df1 and df2 if instead of 'key', each had the same column named as 'key1' and 'key2', respectively. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'key1': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data1': range(7)})\n",
    "df4 = pd.DataFrame({'key2': ['a', 'b', 'd'],'data2': range(3)})\n",
    "\n",
    "import pandas as pd\n",
    "pd.merge(df3,df4,left_on = 'key1', right_on='key2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `merge()` performs an <i>inner join</i>. If we want to do other types of join, we have to specify using `how`. Can you guess the `pandas` expression for a left join between df1 and df2? What about an outer join? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.merge(df1,df2,on='key',how='left')\n",
    "pd.merge(df1,df2,on='key',how='outer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following dataframes: \n",
    "````\n",
    "left = pd.DataFrame({'key1': ['foo', 'foo', 'bar'],'key2': ['one', 'two', 'one'],'lval': [1, 2, 3]})\n",
    "right = pd.DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'],'key2': ['one', 'one', 'one', 'two'],'rval': [4, 5, 6, 7]})\n",
    "````\n",
    "If we want to do an <i>outer</i> join between two datasets, we specify `how = 'outer'` within the method `merge()`. Also, if we want to join using two simultaneous keys, we can pass them as a list `(['key1','key2'])`. Knowing this, what would be the command to do a left join using both keys on the datasets we've just defined (left, right)? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key1': ['foo', 'foo', 'bar'],\n",
    "                     'key2': ['one', 'two', 'one'],\n",
    "                     'lval': [1, 2, 3]})\n",
    "                     \n",
    "right = pd.DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'],\n",
    "                      'key2': ['one', 'one', 'one', 'two'],\n",
    "                      'rval': [4, 5, 6, 7]})\n",
    "                      \n",
    "pd.merge(left,right,how='left',on=['key1','key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "left1  = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],'value': range(6)})\n",
    "right1 = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "left1  = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],'value': range(6)})\n",
    "left1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "right1 = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])\n",
    "\n",
    "right1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "We can also `merge()` by the index instead of using columns. Suppose we have the following datasets: \n",
    "\n",
    "````\n",
    "left1 = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],'value': range(6)})\n",
    "\n",
    "right1 = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b']) \n",
    "````\n",
    "\n",
    "If we apply the following command, the resulting dataframe will have a missing value. Why? \n",
    "\n",
    "````\n",
    "pd.merge(left1, right1, left_on = 'key', right_index = True, how = 'outer')\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "#Answer: \n",
    "# In the example above, we're joining a dataframe of column 'key', \n",
    "# with the unique values of 'a','b' and 'c' with the index of a dataframe \n",
    "# with unique values of 'a' and 'b'. Therefore, the line corresponding to \n",
    "# the key 'c' will be missing. \n",
    "\n",
    "left1  = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],'value': range(6)})\n",
    "right1 = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])\n",
    "\n",
    "pd.merge(left1, right1, left_on = 'key', right_index = True, how = 'outer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "It is also possible to merge using indexes on both side. Suppose we have the following dataframes: \n",
    "````\n",
    "right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]], index=['b', 'c', 'd', 'e'], columns=['Missouri', 'Alabama'])\n",
    "left2  = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]], index=['a', 'c', 'e'], columns=['Ohio', 'Nevada'])\n",
    "````\n",
    "Based on your previous knowledge, what would be the command to <i>outer</i> join 'left2' and 'right2' by their indexes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]], \n",
    "                        index=['b', 'c', 'd', 'e'], \n",
    "                        columns=['Missouri', 'Alabama'])\n",
    "                        \n",
    "left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]], \n",
    "                        index=['a', 'c', 'e'], \n",
    "                        columns=['Ohio', 'Nevada'])\n",
    "                        \n",
    "pd.merge(left2, right2, how = 'outer', left_index = True, right_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method is `join`, which allows a 'merge' to be done by 'index'. It follows a basic syntax, such as : \n",
    "````\n",
    "dataset_1.join(dataset_2, how='method')\n",
    "````\n",
    "The default `join` operation performs a <i>left join</i>. What's then the correct syntax to perform a `left join` between left2 and right2 dataframes? Which row of right2 would disappear?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# Answer: \n",
    "# The rows with indexes 'b' and 'd'.\n",
    "left2.join(right2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of simply using `merge` or `join` to join two or more dataframes, we could also concatenate them along an axis. For example, we could concatenate the following two Series into one Series following this general procedure: \n",
    "\n",
    "````\n",
    "import pandas as pd\n",
    "\n",
    "Series1 = pd.Series([10,20],index=['x0','x1'])\n",
    "Series2 = pd.Series([30,40],index=['x2','x3'])\n",
    "\n",
    "result = pd.concat([Series1,Series2])\n",
    "\n",
    ">>>\n",
    "x0    10\n",
    "x1    20\n",
    "x2    30\n",
    "x3    40\n",
    "dtype: int64\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "left2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "right2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the previous dataframes left2 and right2 into a single final dataframe with unique indices and show the correct script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pd.concat( [left2,right2] ,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we change the `axis` information in the `concat` method? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "# Answer: We get a pilled dataframe (remember, \n",
    "# axis = 0 is not necessary to indicate, as axis = 0 is default). \n",
    "\n",
    "pd.concat([left2,right2],axis=0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `join = 'inner'` method and modify the command of Exercise 23. What's the final result? Why did this happen? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# Answer: produces a dataframe with only two rows and NO missing value. \n",
    "# This happens because 'inner' joins always look for information that \n",
    "# perfectly matches both dataframes.\n",
    "\n",
    "pd.concat([left2,right2],axis=1,join='inner') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "As previously discussed, we will get back now to the first methods we saw: `stack` and `unstack`. Basically, `stack` rotates the columns in the data and transforms them into rows and `unstack` does the opposite. Let's consider the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "df = pd.DataFrame(np.arange(6).reshape((2, 3)),\r\n",
    "                  index=pd.Index(['Ohio', 'Colorado'], name='state'),\r\n",
    "                  columns=pd.Index(['one', 'two', 'three'],name='number'))\r\n",
    "\r\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "What is the result of the `stack` operation in this dataset? \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# Answer: It produces a 'pandas' series (the columns flip to the rows)\n",
    "df = df.stack()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "Two very important methods in `pandas` are `pivot` and `melt`. Similarly to `stack` and `unstack`, `pivot` and `melt` are inverse operations in a dataframe. Let's consider the following dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key': ['foo', 'bar', 'baz'],\n",
    "                   'A': [1, 2, 3],\n",
    "                   'B': [4, 5, 6],\n",
    "                   'C': [7, 8, 9]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "The output of the following `df.pivot('key','A')`, yields: \r\n",
    "````\r\n",
    "       B              C          \r\n",
    "A      1    2    3    1    2    3\r\n",
    "key                              \r\n",
    "bar  NaN  5.0  NaN  NaN  8.0  NaN\r\n",
    "baz  NaN  NaN  6.0  NaN  NaN  9.0\r\n",
    "foo  4.0  NaN  NaN  7.0  NaN  NaN\r\n",
    "````\r\n",
    "\r\n",
    "What's the command to apply `pivot` to our previous dataframe such that we have 'B' values as rows and 'C' values as columns? \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "df.pivot('B','C')\n",
    "\n",
    "# The first input of the pivot method is telling what will be the row index values (in this case are all the values from column B)\n",
    "# The second input of the pivot method is telling what will be column names values (in this case are all the values from column C)\n",
    "# The \"key\" and \"A\" columns wii be tranfer to the columns level = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "Using `pivot`, a great amount of analysis can be performed (we will later explore these methods using heatmaps). A third parameter can be added to the `pivot` method, in order to explicitly define which values we want to observe in our \"pivoted\" table. The general syntax is: \r\n",
    "\r\n",
    "````\r\n",
    "pivot(index=None, columns=None, values=None) \r\n",
    "````\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the output of the following code? \n",
    "````\n",
    "df.pivot('A','B','C')\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "## The diagonal values are the 'C' values corresponding to the\n",
    "# intersection between 'A' and 'B' columns\n",
    "\n",
    "df.pivot('A','B','C')\n",
    "\n",
    "# The first input will be the rows index values\n",
    "# The second input will be the columns names\n",
    "# The third input will be the values to appear in the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "What about this?\r\n",
    "````\r\n",
    "df.pivot('key','B','key')\r\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df.pivot('key','B','key')\n",
    "\n",
    "# In this case:\n",
    "# the row index values are the values from key column\n",
    "# the column names are the values from B column\n",
    "# the values that are appearing are from key column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "Let's see what happens when we apply `melt` to our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "pd.melt(df,['key'])\n",
    "\n",
    "#The first input is the dataframe we want to melt\n",
    "# The second element is the variables who will be the IDs of the new dataframe\n",
    "# all the others will be \"melted\"\n",
    "# i.e., all the columns names (except the ones in the second input) will be \"unpivoted\" to the row axis\n",
    "# This ways, two new columns are created (in place of all others): \"variable\" and \"value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "What's the result of the following expression?\r\n",
    "````\r\n",
    "pd.melt(df,['key']).pivot('key','variable','value')\r\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "## pivot and melt are opposite operations\n",
    "\n",
    "pd.melt(df,['key']).pivot('key','variable','value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "`melt` can also be used in multiple columns. Write an expression to \"melt\" two columns and to compute the values of two other columns simulteaneously.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "\r\n",
    "#Answer: Any combination of two would suffice this inquiry, for example: \r\n",
    "pd.melt(df,['key','A'],['B','C'])\r\n",
    "pd.melt(df,['key','B'],['A','C'])\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2.0.0",
   "language": "python",
   "name": "spark2"
  },
  "language_info": {
   "codemirror_mode": "text/python",
   "file_extension": ".py",
   "mimetype": "text/python",
   "name": "scala",
   "pygments_lexer": "python",
   "version": "3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
